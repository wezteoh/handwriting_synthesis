{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find gpu\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data\n",
    "train_data = np.load('train_data.npy')\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsize = 20\n",
    "train_data = torch.from_numpy(train_data)\n",
    "if cuda:\n",
    "    train_data.cuda()\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=bsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparamters\n",
    "timesteps = 300\n",
    "num_clusters = 20\n",
    "cell_size = 400\n",
    "nlayers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-layer lstm with mixture of gaussian parameters as outputs\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size = 3, hidden_size = cell_size, num_layers = nlayers, batch_first=True)\n",
    "        self.linear1 = nn.Linear(cell_size, 1+ num_clusters*6)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x, prev):\n",
    "        timesteps = x.shape[1]\n",
    "        h, (h_n, c_n) = self.lstm(x, prev)\n",
    "        params = self.linear1(h)\n",
    "        weights = F.softmax(params.narrow(-1, 0, num_clusters), dim=-1)\n",
    "        mu_1 = params.narrow(-1, num_clusters, num_clusters)\n",
    "        mu_2 = params.narrow(-1, 2*num_clusters, num_clusters)\n",
    "        log_sigma_1 = params.narrow(-1, 3*num_clusters, num_clusters)\n",
    "        log_sigma_2 = params.narrow(-1, 4*num_clusters, num_clusters)\n",
    "        p = self.tanh(params.narrow(-1, 5*num_clusters, num_clusters))\n",
    "        end = F.sigmoid(params.narrow(-1, 6*num_clusters, 1))\n",
    "        \n",
    "        return end, weights, mu_1, mu_2, log_sigma_1, log_sigma_2, p, (h_n, c_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test forward pass\n",
    "# test_batch = Variable(torch.from_numpy(train_data[:20]).narrow(1,0,300),requires_grad=False)\n",
    "# e, w, m_1, m_2, s_1, s_2, p, prev = model(test_batch)\n",
    "# for _ in [e,w,m_1,m_2,s_1, s_2, p]:\n",
    "#     print(_.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(end, weights, mu_1, mu_2, log_sigma_1, log_sigma_2, p, x):\n",
    "    timesteps = x.shape[1]\n",
    "    x_0 = x.narrow(-1,0,1)\n",
    "    x_1 = x.narrow(-1,1,1)\n",
    "    x_2 = x.narrow(-1,2,1)\n",
    "    end_loglik = (x_0*end + (1-x_0)*(1-end)).log()\n",
    "    const = 1E-20\n",
    "    z = (x_1 - mu_1)**2/(log_sigma_1.exp()**2+const)\\\n",
    "        + ((x_2 - mu_2)/(log_sigma_2.exp()+const))**2 \\\n",
    "        - 2*p*(x_1-mu_1)*(x_2-mu_2)/((log_sigma_1 + log_sigma_2).exp()+const)\n",
    "    mog_lik1 = -log_sigma_1 - log_sigma_2 - 0.5*(1-p**2).log()\n",
    "    mog_lik2 = (z.log()-(2*(1-p**2)).log()).exp()\n",
    "    mog_lik = (weights.log() + (mog_lik1 - mog_lik2)).exp().sum(dim=-1)\n",
    "    return end_loglik.sum() + (mog_lik+const).log().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "epochs = 3\n",
    "optimizer = optim.Adam([\n",
    "                {'params':model.parameters()},\n",
    "            ], lr=1e-3)\n",
    "\n",
    "train_loss = 0\n",
    "h_init, c_init = torch.zeros((2,1,cell_size)), torch.zeros((2,1,cell_size))\n",
    "zero_tensor = torch.zeros((bsize, 1, 3))\n",
    "if cuda:\n",
    "    h_init.cuda()\n",
    "    c_init.cuda()\n",
    "    zero_tensor.cuda()\n",
    "h_init, c_init = Variable(h_init), Variable(c_init)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        step_back = torch.cat([zero_tensor, data.narrow(1,0,timesteps-1)], 1)\n",
    "        x = Variable(step_back, requires_grad=False)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        end, weights, mu_1, mu_2, log_sigma_1, log_sigma_2, p , prev= model(x, (h_init, c_init))\n",
    "        y = Variable(data, requires_grad=False)\n",
    "        loss = -log_likelihood(end, weights, mu_1, mu_2, log_sigma_1, log_sigma_2, p, y)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch+1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data[0] / len(data)))\n",
    "            \n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch+1, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unconditionally(steps=300, random_seed=1):\n",
    "    torch.manual_seed(random_seed)\n",
    "    zero_tensor = torch.zeros((1,1,3))\n",
    "    h_init, c_init = torch.zeros((2,1,cell_size)), torch.zeros((2,1,cell_size))\n",
    "    if cuda:\n",
    "        zero_tensor.cuda()\n",
    "        h_init.cuda()\n",
    "        c_init.cuda()\n",
    "    x = Variable(zero_tensor)\n",
    "    h_init, c_init = Variable(h_init), Variable(c_init)\n",
    "    prev = (h_init, c_init)\n",
    "\n",
    "    record = []\n",
    "    # greedy but not the right generation\n",
    "    for i in range(steps):        \n",
    "        end, weights, mu_1, mu_2, log_sigma_1, log_sigma_2, p , prev = model(x, prev)\n",
    "        index = np.random.choice(range(20),p = weights.data[0][0].numpy())\n",
    "        prob_end = end.data[0][0][0]\n",
    "        exp_1 = mu_1.data[0][0][index]\n",
    "        exp_2 = mu_2.data[0][0][index]\n",
    "        out = np.array([np.round(prob_end), exp_1, exp_2])\n",
    "        record.append(out)\n",
    "        x = torch.from_numpy(out).type(torch.FloatTensor)\n",
    "        if cuda:\n",
    "            x.cuda()\n",
    "        x = Variable(x, requires_grad=False)\n",
    "        x = x.view((1,1,3))\n",
    "    return np.array(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(range(20),p = weights.data[0][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = generate_unconditionally()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'..')\n",
    "from utils import plot_stroke\n",
    "plot_stroke(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
